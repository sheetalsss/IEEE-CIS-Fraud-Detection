{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T03:51:38.270094Z",
     "start_time": "2025-12-07T03:51:38.266085Z"
    }
   },
   "source": [
    "import json, joblib, numpy as np, pandas as pd\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.externals.array_api_compat.numpy import full_like\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, auc\n",
    "import shap"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:51:39.260691Z",
     "start_time": "2025-12-07T03:51:38.589251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model  = joblib.load('models/xgb_day6.joblib')\n",
    "full = pd.read_parquet('data/processed/train_full_with_day6.parquet')\n",
    "feature_cols = [c for c in full.columns if c not in ('TransactionID', 'isFraud', 'dt', 'TransactionDT')]"
   ],
   "id": "50c2c403675514",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:55:14.306056Z",
     "start_time": "2025-12-07T03:55:14.300449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get booster feature names (model's training features)\n",
    "booster = model.get_booster()\n",
    "trained_feats = booster.feature_names\n",
    "print(\"Model expects\", len(trained_feats), \"features. Sample:\", trained_feats[:10])\n"
   ],
   "id": "f652a52e90916172",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model expects 485 features. Sample: ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:51:39.725260Z",
     "start_time": "2025-12-07T03:51:39.716055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# After this, every feature should be a numeric dtype\n",
    "bad = [c for c in feature_cols if full[c].dtype not in ('int8','int16','int32','int64','float16','float32','float64')]\n",
    "if bad:\n",
    "    print(\"Non-numeric columns still present:\", bad)\n",
    "else:\n",
    "    print(\"All feature columns numeric. Good to go.\")"
   ],
   "id": "3a4daf1eff48e869",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns still present: ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'P_email_provider', 'R_email_provider']\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:51:40.535327Z",
     "start_time": "2025-12-07T03:51:40.470047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) normalize dtypes for all feature columns on the master 'full' DataFrame\n",
    "#    This ensures train/val/test use the exact same integer encodings.\n",
    "feat = feature_cols  # from previous cell\n",
    "\n",
    "for c in feat:\n",
    "    # If object -> convert to categorical and then to codes\n",
    "    if full[c].dtype == 'object':\n",
    "        full[c] = full[c].astype('category')\n",
    "    # If it's categorical, convert to integer codes (preserves mapping since full is master)\n",
    "    if str(full[c].dtype) == 'category':\n",
    "        full[c] = full[c].cat.codes.astype('int32')\n",
    "    # If it's boolean, convert to int\n",
    "    if full[c].dtype == 'bool':\n",
    "        full[c] = full[c].astype('int8')"
   ],
   "id": "13fa100fd2a26367",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:51:42.056465Z",
     "start_time": "2025-12-07T03:51:41.595559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = len(full)\n",
    "te = int(0.70*n)\n",
    "ve = int(0.85*n)\n",
    "\n",
    "X_train = full.iloc[:te][feature_cols]\n",
    "y_train = full.iloc[:te]['isFraud'].astype(int)\n",
    "X_val = full.iloc[te:ve][feature_cols]\n",
    "y_val = full.iloc[te:ve]['isFraud'].astype(int)\n",
    "X_test = full.iloc[ve:][feature_cols]\n",
    "y_test = full.iloc[ve:]['isFraud'].astype(int)"
   ],
   "id": "cd04204f230e4a71",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:51:43.603227Z",
     "start_time": "2025-12-07T03:51:43.255245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3 quick sanity checks\n",
    "print(\"Dtypes sample:\", {c: str(full[c].dtype) for c in feat[:10]})\n",
    "print(\"Splits shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Any NaNs in features:\", X_train.isna().any().any(), X_val.isna().any().any(), X_test.isna().any().any())"
   ],
   "id": "b16ff4cb12f41ac4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtypes sample: {'TransactionAmt': 'float32', 'ProductCD': 'int32', 'card1': 'int32', 'card2': 'float32', 'card3': 'float32', 'card4': 'int32', 'card5': 'float32', 'card6': 'int32', 'addr1': 'float32', 'addr2': 'float32'}\n",
      "Splits shapes: (413378, 488) (88581, 488) (88581, 488)\n",
      "Any NaNs in features: True True True\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:51:57.287485Z",
     "start_time": "2025-12-07T03:51:57.181067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# applying Platt scaling (sigmoid) to turn raw XGB scores into better-calibrated probabilities.\n",
    "# cv='prefit' means we fit a small logistic on model scores using val set.\n",
    "\n",
    "# tree models often output overconfident scores. Calibrated probabilities are actionable for thresholds, SLAs, and precision-at-k business decisions.\n",
    "from sklearn.calibration import CalibratedClassifierCV, FrozenEstimator\n",
    "frozen = FrozenEstimator(model)\n",
    "cal = CalibratedClassifierCV(frozen, method='sigmoid', cv=\"prefit\")\n",
    "cal.fit(X_val, y_val)   # now X_val has only numeric dtypes"
   ],
   "id": "40d19608497af176",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'P_email_provider', 'R_email_provider', 'email_domain_mismatch', 'P_emaildomain_freq', 'R_emaildomain_freq', 'P_email_provider_freq', 'R_email_provider_freq', 'P_email_rare', 'R_email_rare', 'device_freq', 'is_rare_device', 'device_type_freq', 'addr1_freq', 'addr2_freq', 'id_01_freq', 'id_02_freq', 'id_03_freq', 'id_04_freq', 'id_05_freq', 'id_06_freq', 'id_07_freq', 'id_08_freq', 'id_09_freq', 'id_10_freq', 'id_11_freq', 'id_12_freq', 'id_13_freq', 'id_14_freq', 'id_15_freq', 'id_16_freq', 'id_17_freq', 'id_18_freq', 'id_19_freq', 'id_20_freq', 'id_21_freq', 'id_22_freq', 'id_23_freq', 'id_24_freq', 'id_25_freq', 'id_26_freq', 'id_27_freq', 'id_28_freq', 'id_29_freq', 'id_30_freq', 'id_31_freq', 'id_32_freq', 'id_33_freq', 'id_34_freq', 'id_35_freq', 'id_36_freq', 'id_37_freq', 'id_38_freq', 'id_17_rare', 'id_31_rare', 'id_33_rare', 'card1_freq', 'card6_freq'] ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'P_email_provider', 'R_email_provider', 'email_domain_mismatch', 'P_emaildomain_freq', 'R_emaildomain_freq', 'P_email_provider_freq', 'R_email_provider_freq', 'P_email_rare', 'R_email_rare', 'device_freq', 'is_rare_device', 'device_type_freq', 'addr1_freq', 'addr2_freq', 'id_01_freq', 'id_02_freq', 'id_03_freq', 'id_04_freq', 'id_05_freq', 'id_06_freq', 'id_07_freq', 'id_08_freq', 'id_09_freq', 'id_10_freq', 'id_11_freq', 'id_12_freq', 'id_13_freq', 'id_14_freq', 'id_15_freq', 'id_16_freq', 'id_17_freq', 'id_18_freq', 'id_19_freq', 'id_20_freq', 'id_21_freq', 'id_22_freq', 'id_23_freq', 'id_24_freq', 'id_25_freq', 'id_26_freq', 'id_27_freq', 'id_28_freq', 'id_29_freq', 'id_30_freq', 'id_31_freq', 'id_32_freq', 'id_33_freq', 'id_34_freq', 'id_35_freq', 'id_36_freq', 'id_37_freq', 'id_38_freq', 'id_17_rare', 'id_31_rare', 'id_33_rare', 'card1_freq', 'card6_freq']\ntraining data did not have the following fields: R_emaildomain, DeviceInfo, P_emaildomain",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m frozen = FrozenEstimator(model)\n\u001B[32m      7\u001B[39m cal = CalibratedClassifierCV(frozen, method=\u001B[33m'\u001B[39m\u001B[33msigmoid\u001B[39m\u001B[33m'\u001B[39m, cv=\u001B[33m\"\u001B[39m\u001B[33mprefit\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[43mcal\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m   \u001B[38;5;66;03m# now X_val has only numeric dtypes\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1365\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1358\u001B[39m     estimator._validate_params()\n\u001B[32m   1360\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1361\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1362\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1363\u001B[39m     )\n\u001B[32m   1364\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1365\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/calibration.py:340\u001B[39m, in \u001B[36mCalibratedClassifierCV.fit\u001B[39m\u001B[34m(self, X, y, sample_weight, **fit_params)\u001B[39m\n\u001B[32m    337\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m.estimator, attributes=[\u001B[33m\"\u001B[39m\u001B[33mclasses_\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    338\u001B[39m \u001B[38;5;28mself\u001B[39m.classes_ = \u001B[38;5;28mself\u001B[39m.estimator.classes_\n\u001B[32m--> \u001B[39m\u001B[32m340\u001B[39m predictions, _ = \u001B[43m_get_response_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    342\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    343\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresponse_method\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdecision_function\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpredict_proba\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    344\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    345\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m predictions.ndim == \u001B[32m1\u001B[39m:\n\u001B[32m    346\u001B[39m     \u001B[38;5;66;03m# Reshape binary output from `(n_samples,)` to `(n_samples, 1)`\u001B[39;00m\n\u001B[32m    347\u001B[39m     predictions = predictions.reshape(-\u001B[32m1\u001B[39m, \u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_response.py:214\u001B[39m, in \u001B[36m_get_response_values\u001B[39m\u001B[34m(estimator, X, response_method, pos_label, return_response_method_used)\u001B[39m\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m pos_label \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m target_type == \u001B[33m\"\u001B[39m\u001B[33mbinary\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    212\u001B[39m         pos_label = classes[-\u001B[32m1\u001B[39m]\n\u001B[32m--> \u001B[39m\u001B[32m214\u001B[39m y_pred = \u001B[43mprediction_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m prediction_method.\u001B[34m__name__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m (\u001B[33m\"\u001B[39m\u001B[33mpredict_proba\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mpredict_log_proba\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    217\u001B[39m     y_pred = _process_predict_proba(\n\u001B[32m    218\u001B[39m         y_pred=y_pred,\n\u001B[32m    219\u001B[39m         target_type=target_type,\n\u001B[32m    220\u001B[39m         classes=classes,\n\u001B[32m    221\u001B[39m         pos_label=pos_label,\n\u001B[32m    222\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/sklearn.py:1798\u001B[39m, in \u001B[36mXGBClassifier.predict_proba\u001B[39m\u001B[34m(self, X, validate_features, base_margin, iteration_range)\u001B[39m\n\u001B[32m   1796\u001B[39m     class_prob = softmax(raw_predt, axis=\u001B[32m1\u001B[39m)\n\u001B[32m   1797\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m class_prob\n\u001B[32m-> \u001B[39m\u001B[32m1798\u001B[39m class_probs = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1799\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1800\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1801\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1802\u001B[39m \u001B[43m    \u001B[49m\u001B[43miteration_range\u001B[49m\u001B[43m=\u001B[49m\u001B[43miteration_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1803\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1804\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _cls_predict_proba(\u001B[38;5;28mself\u001B[39m.n_classes_, class_probs, np.vstack)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/core.py:729\u001B[39m, in \u001B[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    727\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig.parameters, args):\n\u001B[32m    728\u001B[39m     kwargs[k] = arg\n\u001B[32m--> \u001B[39m\u001B[32m729\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/sklearn.py:1327\u001B[39m, in \u001B[36mXGBModel.predict\u001B[39m\u001B[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001B[39m\n\u001B[32m   1325\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._can_use_inplace_predict():\n\u001B[32m   1326\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1327\u001B[39m         predts = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_booster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43minplace_predict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1328\u001B[39m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1329\u001B[39m \u001B[43m            \u001B[49m\u001B[43miteration_range\u001B[49m\u001B[43m=\u001B[49m\u001B[43miteration_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1330\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpredict_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmargin\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput_margin\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvalue\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1331\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmissing\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1332\u001B[39m \u001B[43m            \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1333\u001B[39m \u001B[43m            \u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1334\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1335\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m _is_cupy_alike(predts):\n\u001B[32m   1336\u001B[39m             cp = import_cupy()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/core.py:729\u001B[39m, in \u001B[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    727\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig.parameters, args):\n\u001B[32m    728\u001B[39m     kwargs[k] = arg\n\u001B[32m--> \u001B[39m\u001B[32m729\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/core.py:2667\u001B[39m, in \u001B[36mBooster.inplace_predict\u001B[39m\u001B[34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001B[39m\n\u001B[32m   2665\u001B[39m     data, fns, _ = _transform_pandas_df(data, enable_categorical)\n\u001B[32m   2666\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m validate_features:\n\u001B[32m-> \u001B[39m\u001B[32m2667\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_validate_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2668\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _is_list(data) \u001B[38;5;129;01mor\u001B[39;00m _is_tuple(data):\n\u001B[32m   2669\u001B[39m     data = np.array(data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/xgboost/core.py:3243\u001B[39m, in \u001B[36mBooster._validate_features\u001B[39m\u001B[34m(self, feature_names)\u001B[39m\n\u001B[32m   3237\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m my_missing:\n\u001B[32m   3238\u001B[39m     msg += (\n\u001B[32m   3239\u001B[39m         \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mtraining data did not have the following fields: \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   3240\u001B[39m         + \u001B[33m\"\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m.join(\u001B[38;5;28mstr\u001B[39m(s) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m my_missing)\n\u001B[32m   3241\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m3243\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg.format(\u001B[38;5;28mself\u001B[39m.feature_names, feature_names))\n",
      "\u001B[31mValueError\u001B[39m: feature_names mismatch: ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'P_email_provider', 'R_email_provider', 'email_domain_mismatch', 'P_emaildomain_freq', 'R_emaildomain_freq', 'P_email_provider_freq', 'R_email_provider_freq', 'P_email_rare', 'R_email_rare', 'device_freq', 'is_rare_device', 'device_type_freq', 'addr1_freq', 'addr2_freq', 'id_01_freq', 'id_02_freq', 'id_03_freq', 'id_04_freq', 'id_05_freq', 'id_06_freq', 'id_07_freq', 'id_08_freq', 'id_09_freq', 'id_10_freq', 'id_11_freq', 'id_12_freq', 'id_13_freq', 'id_14_freq', 'id_15_freq', 'id_16_freq', 'id_17_freq', 'id_18_freq', 'id_19_freq', 'id_20_freq', 'id_21_freq', 'id_22_freq', 'id_23_freq', 'id_24_freq', 'id_25_freq', 'id_26_freq', 'id_27_freq', 'id_28_freq', 'id_29_freq', 'id_30_freq', 'id_31_freq', 'id_32_freq', 'id_33_freq', 'id_34_freq', 'id_35_freq', 'id_36_freq', 'id_37_freq', 'id_38_freq', 'id_17_rare', 'id_31_rare', 'id_33_rare', 'card1_freq', 'card6_freq'] ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1', 'dist2', 'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'P_email_provider', 'R_email_provider', 'email_domain_mismatch', 'P_emaildomain_freq', 'R_emaildomain_freq', 'P_email_provider_freq', 'R_email_provider_freq', 'P_email_rare', 'R_email_rare', 'device_freq', 'is_rare_device', 'device_type_freq', 'addr1_freq', 'addr2_freq', 'id_01_freq', 'id_02_freq', 'id_03_freq', 'id_04_freq', 'id_05_freq', 'id_06_freq', 'id_07_freq', 'id_08_freq', 'id_09_freq', 'id_10_freq', 'id_11_freq', 'id_12_freq', 'id_13_freq', 'id_14_freq', 'id_15_freq', 'id_16_freq', 'id_17_freq', 'id_18_freq', 'id_19_freq', 'id_20_freq', 'id_21_freq', 'id_22_freq', 'id_23_freq', 'id_24_freq', 'id_25_freq', 'id_26_freq', 'id_27_freq', 'id_28_freq', 'id_29_freq', 'id_30_freq', 'id_31_freq', 'id_32_freq', 'id_33_freq', 'id_34_freq', 'id_35_freq', 'id_36_freq', 'id_37_freq', 'id_38_freq', 'id_17_rare', 'id_31_rare', 'id_33_rare', 'card1_freq', 'card6_freq']\ntraining data did not have the following fields: R_emaildomain, DeviceInfo, P_emaildomain"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51654b724165db84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2ab6bf6746faeaa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ---- calibration (Platt) ----\n",
    "cal = CalibratedClassifierCV(model, method='sigmoid', cv='prefit')\n",
    "cal.fit(X_val, y_val)\n",
    "joblib.dump(cal, \"models/xgb_day7_calibrated.joblib\")\n",
    "\n",
    "# ---- threshold search on val ----\n",
    "probs_val = cal.predict_proba(X_val)[:,1]\n",
    "ths = np.linspace(0.01,0.99,200)\n",
    "f1s = [f1_score(y_val, probs_val>t) for t in ths]\n",
    "best_f1_t = float(ths[np.argmax(f1s)])\n",
    "# precision@k (top k fraction)\n",
    "def top_k_capture(y_true, probs, k=0.01):\n",
    "    kN = max(1,int(len(probs)*k))\n",
    "    idx = np.argsort(probs)[::-1][:kN]\n",
    "    return y_true.iloc[idx].mean()\n",
    "top1_val = top_k_capture(y_val, probs_val, 0.01)\n",
    "\n",
    "# ---- test metrics at best_f1_t ----\n",
    "probs_test = cal.predict_proba(X_test)[:,1]\n",
    "roc_test = roc_auc_score(y_test, probs_test)\n",
    "prec, rec, _ = precision_recall_curve(y_test, probs_test)\n",
    "pr_test = auc(rec, prec)\n",
    "pred_test = (probs_test > best_f1_t).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test, pred_test, digits=4)\n",
    "top1_test = top_k_capture(y_test, probs_test, 0.01)\n",
    "\n",
    "# ---- stability per month ----\n",
    "if 'dt' in full.columns:\n",
    "    full['month'] = full['dt'].dt.to_period('M')\n",
    "    months = sorted(full['month'].unique())\n",
    "    month_stats=[]\n",
    "    for m in months:\n",
    "        mask = full['month']==m\n",
    "        if mask.sum()<50: continue\n",
    "        p = cal.predict_proba(full.loc[mask, feature_cols])[:,1]\n",
    "        month_stats.append((str(m), float(roc_auc_score(full.loc[mask,'isFraud'], p))))\n",
    "else:\n",
    "    month_stats=[]\n",
    "\n",
    "# ---- SHAP (sample) ----\n",
    "sample_idx = X_test.sample(2000, random_state=42).index\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test.loc[sample_idx])\n",
    "# save a small summary (top features by mean|shap|)\n",
    "shap_mean = np.abs(shap_values).mean(axis=0)\n",
    "top_shap = list(pd.Series(shap_mean, index=feature_cols).sort_values(ascending=False).head(10).index)\n",
    "\n",
    "# ---- save thresholds + summary ----\n",
    "out = {\n",
    "  \"best_f1_threshold\": best_f1_t,\n",
    "  \"top1_val_capture\": float(top1_val),\n",
    "  \"roc_test\": float(roc_test),\n",
    "  \"pr_test\": float(pr_test),\n",
    "  \"top1_test_capture\": float(top1_test),\n",
    "  \"top_shap_features\": top_shap,\n",
    "  \"month_roc\": month_stats\n",
    "}\n",
    "with open(\"models/day7_summary.json\",\"w\") as f: json.dump(out,f,indent=2)\n",
    "print(\"SAVED: models/xgb_day7_calibrated.joblib, models/day7_summary.json\")\n",
    "\n",
    "# ---- print deliverables ----\n",
    "print(\"\\n--- DELIVERABLES ---\")\n",
    "print(f\"Best F1 threshold (val): {best_f1_t:.4f}\")\n",
    "print(f\"ROC test: {roc_test:.4f}  PR-AUC test: {pr_test:.4f}\")\n",
    "print(\"Top-1% test capture:\", round(top1_test,4))\n",
    "print(\"\\nClassification report at best threshold:\\n\", cr)\n",
    "print(\"Top SHAP features:\", top_shap)\n",
    "print(\"Month-wise ROC (sample):\", month_stats[:10])\n"
   ],
   "id": "97af211abfe91cc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2ec7f40ee1e26b55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c07a14385e682de3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "967503fba95f1143"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:56:12.730686Z",
     "start_time": "2025-12-07T03:56:11.215306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib, numpy as np, pandas as pd\n",
    "from sklearn.calibration import CalibratedClassifierCV, FrozenEstimator\n",
    "\n",
    "# load model & data\n",
    "model = joblib.load(\"models/xgb_day6.joblib\")\n",
    "full = pd.read_parquet(\"data/processed/train_full_with_day6.parquet\")\n",
    "\n",
    "# get booster feature names (model's training features)\n",
    "booster = model.get_booster()\n",
    "trained_feats = booster.feature_names\n",
    "print(\"Model expects\", len(trained_feats), \"features. Sample:\", trained_feats[:10])\n",
    "\n",
    "# pick same positional splits\n",
    "n=len(full); te=int(0.70*n); ve=int(0.85*n)\n",
    "\n",
    "# create X_val_raw from full (all candidate features)\n",
    "# we’ll force alignment to trained_feats below\n",
    "X_val_raw = full.iloc[te:ve].copy()\n",
    "y_val = full.iloc[te:ve]['isFraud'].astype(int)\n",
    "\n",
    "# 1) Add missing features (that model expects but are not in X_val_raw)\n",
    "miss = [c for c in trained_feats if c not in X_val_raw.columns]\n",
    "if miss:\n",
    "    print(\"Adding missing columns (filled -999):\", miss[:20], \"… total\", len(miss))\n",
    "    for c in miss:\n",
    "        X_val_raw[c] = -999\n",
    "\n",
    "# 2) Drop unexpected extras (not needed but harmless)\n",
    "extra = [c for c in X_val_raw.columns if c not in trained_feats]\n",
    "if extra:\n",
    "    print(\"Dropping extra columns not in model (sample):\", extra[:20], \"… total\", len(extra))\n",
    "    X_val_raw = X_val_raw.drop(columns=extra)\n",
    "\n",
    "# 3) Reorder exactly as model.feature_names\n",
    "X_val_aligned = X_val_raw[trained_feats].copy()\n",
    "\n",
    "# 4) Ensure numeric dtypes: convert object/categorical/bool -> numeric codes or ints\n",
    "for c in X_val_aligned.columns:\n",
    "    if X_val_aligned[c].dtype == 'object':\n",
    "        X_val_aligned[c] = X_val_aligned[c].astype('category').cat.codes\n",
    "    if str(X_val_aligned[c].dtype).startswith('category'):\n",
    "        X_val_aligned[c] = X_val_aligned[c].cat.codes\n",
    "    if X_val_aligned[c].dtype == 'bool':\n",
    "        X_val_aligned[c] = X_val_aligned[c].astype('int8')\n",
    "\n",
    "# 5) Fill NaNs (match training fill strategy)\n",
    "X_val_aligned = X_val_aligned.fillna(-999)\n",
    "\n",
    "# quick sanity\n",
    "print(\"Final X_val shape:\", X_val_aligned.shape)\n",
    "non_numeric = [c for c in X_val_aligned.columns if X_val_aligned[c].dtype not in (np.int8,np.int16,np.int32,np.int64,np.float16,np.float32,np.float64)]\n",
    "print(\"Non-numeric left:\", non_numeric)\n",
    "\n",
    "# 6) Calibrate using FrozenEstimator (no refit risk)\n",
    "frozen = FrozenEstimator(model)\n",
    "cal = CalibratedClassifierCV(frozen, method='sigmoid', cv=\"prefit\")\n",
    "cal.fit(X_val_aligned, y_val)   # should run without feature mismatch now\n",
    "\n",
    "joblib.dump(cal, \"models/xgb_day7_calibrated.joblib\")\n",
    "print(\"Calibrated model saved to models/xgb_day7_calibrated.joblib\")\n"
   ],
   "id": "3e0ff785ac254ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model expects 485 features. Sample: ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2']\n",
      "Dropping extra columns not in model (sample): ['TransactionID', 'isFraud', 'TransactionDT', 'P_emaildomain', 'R_emaildomain', 'DeviceInfo', 'dt'] … total 7\n",
      "Final X_val shape: (88581, 485)\n",
      "Non-numeric left: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated model saved to models/xgb_day7_calibrated.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/calibration.py:867: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad = np.asarray([-g @ F, -g.sum()], dtype=np.float64)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/calibration.py:867: RuntimeWarning: overflow encountered in matmul\n",
      "  grad = np.asarray([-g @ F, -g.sum()], dtype=np.float64)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/calibration.py:867: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad = np.asarray([-g @ F, -g.sum()], dtype=np.float64)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:59:03.241715Z",
     "start_time": "2025-12-07T03:59:02.700338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# probs on val (from calibrated model you just saved)\n",
    "probs_val = cal.predict_proba(X_val_aligned)[:,1]\n",
    "\n",
    "# distributions & trouble flags\n",
    "import numpy as np, pandas as pd\n",
    "print(\"probs min/median/max:\", probs_val.min(), np.median(probs_val), probs_val.max())\n",
    "print(\"unique probs count:\", np.unique(np.round(probs_val,6)).size)\n",
    "print(\"counts of extreme probs:\", ((probs_val==0).sum(), (probs_val==1).sum()))\n",
    "print(\"val pos count:\", y_val.sum(), \" / \", len(y_val))\n"
   ],
   "id": "dd477ba13dc10219",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs min/median/max: 0.00554740928962251 0.006881584425518473 0.8089915802762615\n",
      "unique probs count: 24078\n",
      "counts of extreme probs: (np.int64(0), np.int64(0))\n",
      "val pos count: 3042  /  88581\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T03:59:33.160130Z",
     "start_time": "2025-12-07T03:59:33.118594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score, classification_report\n",
    "roc_val = roc_auc_score(y_val, probs_val)\n",
    "prec, rec, ths = precision_recall_curve(y_val, probs_val); pr_val = auc(rec, prec)\n",
    "# best F1 on val\n",
    "f1s = [( (prec_i*rec_i*2)/(prec_i+rec_i+1e-9) ) for prec_i,rec_i in zip(prec,rec)]\n",
    "best_idx = np.argmax(f1s)\n",
    "best_th = ths[best_idx-1] if best_idx>0 else 0.5\n",
    "print(\"ROC-val, PR-val:\", roc_val, pr_val, \"best-F1-th:\", best_th)\n"
   ],
   "id": "e91898fa05361ee0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-val, PR-val: 0.9201276837409074 0.5910724257294672 best-F1-th: 0.43383615224333966\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T04:01:29.189767Z",
     "start_time": "2025-12-07T04:01:28.654436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- align + encode + fill for X_test, then evaluate ---\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "# trained_feats, full, ve already exist from earlier cells\n",
    "X_test_raw = full.iloc[ve:].copy()\n",
    "y_test = full.iloc[ve:]['isFraud'].astype(int)\n",
    "\n",
    "# 1) add missing cols model expects\n",
    "miss = [c for c in trained_feats if c not in X_test_raw.columns]\n",
    "for c in miss:\n",
    "    X_test_raw[c] = -999\n",
    "\n",
    "# 2) drop extras\n",
    "extra = [c for c in X_test_raw.columns if c not in trained_feats]\n",
    "if extra:\n",
    "    X_test_raw = X_test_raw.drop(columns=extra)\n",
    "\n",
    "# 3) reorder\n",
    "X_test_raw = X_test_raw[trained_feats].copy()\n",
    "\n",
    "# 4) Convert object/categorical/bool -> numeric codes BEFORE fillna\n",
    "for c in X_test_raw.columns:\n",
    "    if X_test_raw[c].dtype == 'object':\n",
    "        X_test_raw[c] = X_test_raw[c].astype('category')\n",
    "    # If categorical (including those you may have created earlier), convert to codes\n",
    "    if str(X_test_raw[c].dtype).startswith('category'):\n",
    "        # keep -1 for missing categories (cat.codes uses -1)\n",
    "        X_test_raw[c] = X_test_raw[c].cat.codes.astype('int32')\n",
    "    if X_test_raw[c].dtype == 'bool':\n",
    "        X_test_raw[c] = X_test_raw[c].astype('int8')\n",
    "\n",
    "# 5) Now safe to fill NaNs with sentinel\n",
    "X_test_aligned = X_test_raw.fillna(-999)\n",
    "\n",
    "# sanity check\n",
    "non_numeric = [c for c in X_test_aligned.columns if X_test_aligned[c].dtype not in (np.int8,np.int16,np.int32,np.int64,np.float16,np.float32,np.float64)]\n",
    "print(\"Non-numeric after conversion (should be empty):\", non_numeric)\n",
    "print(\"X_test_aligned shape:\", X_test_aligned.shape)\n",
    "\n",
    "# 6) predict & metrics\n",
    "probs_test = cal.predict_proba(X_test_aligned)[:,1]\n",
    "roc_test = roc_auc_score(y_test, probs_test)\n",
    "prec, rec, _ = precision_recall_curve(y_test, probs_test)\n",
    "pr_test = auc(rec, prec)\n",
    "print(\"ROC-test:\", round(roc_test,4), \"PR-test:\", round(pr_test,4))\n"
   ],
   "id": "1f6c6785e8a067b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric after conversion (should be empty): []\n",
      "X_test_aligned shape: (88581, 485)\n",
      "ROC-test: 0.8899 PR-test: 0.5159\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T04:15:43.305314Z",
     "start_time": "2025-12-07T04:15:43.242925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "# probs_val, probs_test, y_val, y_test, best_th already exist\n",
    "\n",
    "# Metrics\n",
    "roc_val = roc_auc_score(y_val, probs_val)\n",
    "roc_test = roc_auc_score(y_test, probs_test)\n",
    "\n",
    "# PR-AUC (robust)\n",
    "pr_val = average_precision_score(y_val, probs_val)\n",
    "pr_test = average_precision_score(y_test, probs_test)\n",
    "\n",
    "print(\"ROC-val:\", round(roc_val,4), \" ROC-test:\", round(roc_test,4))\n",
    "print(\"PR-val (average_precision):\", round(pr_val,4), \" PR-test:\", round(pr_test,4))\n",
    "\n",
    "# Classification report at chosen threshold\n",
    "yhat_test = (probs_test >= best_th).astype(int)\n",
    "print(\"\\nTest classification report (th={:.4f}):\".format(best_th))\n",
    "print(classification_report(y_test, yhat_test, digits=4))\n",
    "\n",
    "# Top-1% fraud capture\n",
    "k = max(1, int(0.01 * len(probs_test)))\n",
    "topk_idx = np.argsort(probs_test)[-k:]\n",
    "# y_test is a pandas Series (aligned); get values at indices\n",
    "top1_frac = y_test.iloc[topk_idx].sum() / (y_test.sum() + 1e-9)\n",
    "print(\"Top-1% fraud capture:\", round(top1_frac,4))\n"
   ],
   "id": "184a75e27cccdcf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-val: 0.9201  ROC-test: 0.8899\n",
      "PR-val (average_precision): 0.5911  PR-test: 0.516\n",
      "\n",
      "Test classification report (th=0.4338):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9798    0.9909    0.9853     85498\n",
      "           1     0.6332    0.4340    0.5150      3083\n",
      "\n",
      "    accuracy                         0.9716     88581\n",
      "   macro avg     0.8065    0.7125    0.7502     88581\n",
      "weighted avg     0.9678    0.9716    0.9690     88581\n",
      "\n",
      "Top-1% fraud capture: 0.2562\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aae356a62b5b260f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
